import os
import numpy as np
import pandas as pd
import geopandas as gpd
import xarray as xr
from shapely.ops import nearest_points
from datetime import datetime, timedelta

#============== Read in Auswave mesh point locations ==============#
def loadMeshPts(meshPts=None, epsg=None):

    df = pd.read_csv(meshPts)
    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))
    ausWaveEPSG = int(epsg)
    gdf.set_crs(epsg=ausWaveEPSG)

    return gdf

#============== Load Auswave output forecast name  ==============#
def loadAuswave(forecast=None, wavesDir=None):

    # Parse date to match Auswave output naming convention
    bomDate = str(str(forecast.roundedTime.year)+
            str(forecast.roundedTime.month).zfill(2)+
            str(forecast.roundedTime.day).zfill(2))
    bomTime = str(str(forecast.roundedTime.hour).zfill(2)+
            str(forecast.roundedTime.minute).zfill(2))
    bomDT = str(bomDate+"T"+bomTime+"Z")
    cityCode = forecast.waveCode
    fname = "%s.msh.%s.nc" % (cityCode,bomDT)

    # Read in output
    ausWavedf = os.path.join(wavesDir, fname)
    ds = xr.open_dataset(ausWavedf)

    return ds

def nearGeom(point, pts=None, gdfIn=None, outVar=None):
    # find the nearest point and return the corresponding Place value
    nearest = gdfIn.geometry == nearest_points(point, pts)[1]
    geometries = gdfIn[nearest].geometry.to_numpy()[0]
    indeces = gdfIn[nearest].index.to_numpy()[0]
    if outVar == "index":
        return indeces
    elif outVar == "geometries":
        return geometries
    else:
        raise

def extractAusWavePts(ds=None, meshPts=None, epsg=None):

    # Convert xarray dataset to geodataframe
    dfPts = pd.DataFrame({"Lon":ds.longitude.values,
                        "Lat":ds.latitude.values})
    gdfPts = gpd.GeoDataFrame(dfPts, geometry=gpd.points_from_xy(dfPts.Lon,dfPts.Lat))
    gdfPts.set_crs(epsg=int(epsg))

    # unary union of the geomtries 
    pts = gdfPts.geometry.unary_union
    # Find the nearest geometries in Auswave output to "points of interest"
    # Return the old Auswave index value for slicing Auswave output

    meshPts["oldIndex"] = meshPts.apply(lambda row: nearGeom(row.geometry, 
                                                            pts=pts, 
                                                            gdfIn=gdfPts, 
                                                            outVar="index"), 
                                                            axis=1)
    indArr = meshPts["oldIndex"].to_numpy()
    ds = ds.isel(node=indArr)

    return ds

def getTimeStep(ds=None):

    #============== Get timestep of timeseries in seconds ==============#
    t2 = ds.coords["time"][1].values
    t1 = ds.coords["time"][0].values
    dt = t2-t1
    dt = dt.astype('timedelta64[s]').astype(int).astype(float)

    return dt

def generateWaveFiles(ds=None, forecast=None,
                      jonSwapParam=3.3,dirSpread=10.,
                      dtbc=1.):

    dt = getTimeStep(ds=ds)
    # Round to 3 decimal places
    roundDec = 3
    for index in np.arange(0,ds.sizes['node']):
        # Extract the wave parameters for each point from forecast
        dfOut = pd.DataFrame({"Datetime_gmt":ds.time[:].values,
                             "Hsig":ds.hs[:,0].values.round(roundDec),
                             "Tp":ds.tp[:,0].values.round(roundDec),
                             "dir":ds.dir[:,0].values.round(roundDec),
                             "JS":jonSwapParam,
                             "dirSpread":dirSpread,
                             "dt_sec":dt.round(roundDec),
                             "dtbc":dtbc}).set_index("Datetime_gmt")
        dfOut.index = pd.to_datetime(dfOut.index)
        # Add 12-hour spin-up timeseries that retains the first values
        # of the wave forecast
        spinUpTime = forecast.spinUpWindow # in hours
        spinUpEndTime = forecast.roundedTime
        spinUpStartTime = spinUpEndTime-(spinUpTime)
        spinUp_series = pd.date_range(start=spinUpStartTime,
                                end=spinUpEndTime-timedelta(seconds=dt),
                                freq=timedelta(seconds=dt))
        spinUp_df = pd.DataFrame({"Datetime_gmt":spinUp_series,
                                  "Hsig":dfOut['Hsig'][0],
                                  "Tp":dfOut['Tp'][0],
                                  "dir":dfOut['dir'][0],
                                  "JS":dfOut['JS'][0],
                                  "dirSpread":dfOut['dirSpread'][0],
                                  "dt_sec":dfOut['dt_sec'][0],
                                  "dtbc":dfOut['dtbc'][0]}).set_index("Datetime_gmt")
        spinUp_df.index = pd.to_datetime(spinUp_df.index)
        # Concatenate spin-up timeseries with real timeseries
        dfOut = pd.concat([spinUp_df,dfOut])

        ofileName = "wavefile%s.txt" % (index+1)
        dfOut.to_csv(os.path.join(forecast.xbWorkDir,ofileName), 
                    sep='\t', header=False, index=False)


def moveWavestoBoundary(meshPts=None, 
                        forecast=None):

    # Load XBeach input files
    xgrd = np.loadtxt(forecast.xgrdPath)
    ygrd = np.loadtxt(forecast.ygrdPath)
    zgrd = np.loadtxt(forecast.zgrdPath)

    # (np.array.shape commands returns rows, columns in that order)
    ncolXB = xgrd.shape[1]
    nrowXB = xgrd.shape[0]
    nx = np.arange(0,nrowXB)
    nx = np.repeat(nx,ncolXB)
    ny = np.arange(0,ncolXB)
    ny = np.tile(ny,nrowXB)
    xbgdf = pd.DataFrame({'globalx':xgrd.flatten(),
                           'globaly':ygrd.flatten(),
                           'zb':zgrd.flatten()})
    xbgdf['nx'] = nx
    xbgdf['ny'] = ny
    xbgdf = xbgdf.set_index(['nx','ny'])

    # Convert to geodataframe to do point searching
    #xbgdf = xbds.to_dataframe()
    #print(xbgdf.head())
    xbgdf = gpd.GeoDataFrame(xbgdf, geometry=gpd.points_from_xy(xbgdf.globalx,xbgdf.globaly))
    xbEPSG = int(forecast.xbeachEPSG)
    xbgdf.set_crs(xbEPSG)

    # Using points of interest (now in ds), find closest points on XBeach mesh,
    # return value of index in XBeach output
    # Reproject points to projection used in XBeach
    gdf_proj = meshPts.copy()
    gdf_proj.set_crs(epsg=forecast.auswaveEPSG, inplace=True)
    gdf_proj['geometry'] = gdf_proj['geometry'].to_crs(epsg=xbEPSG)
    # unary union of the geomtries 
    pts = xbgdf.geometry.unary_union
    gdf_proj["xbIndex"] = gdf_proj.apply(lambda row: 
                     nearGeom(row.geometry, pts=pts, gdfIn=xbgdf, outVar="index"), axis=1)


    # Grab the index in the relevant row, first column
    # Column indeces go up starting from seaward points
    # Split xbeach indeces into separate rows, cols
    indList = gdf_proj.xbIndex.tolist()
    gdf_proj[["xbcol","xbrow"]] = pd.DataFrame(indList, index=gdf_proj.index)
    gdf_proj['targetCol'] = 0 # First column, starting from seaward boundary
    gdf_proj['targetRow'] = gdf_proj.xbrow

    # Grab relevant geometries from XBeach grid using target indeces
    # Slice by desired cols first
    #gdf_proj['targetX'] = xbgdf.loc[0]
    targetColArr = gdf_proj['targetCol'].values
    targetRowArr = gdf_proj['targetRow'].values
    targetInd = zip(targetColArr,targetRowArr)
    xbgdf_subset = xbgdf.loc[targetInd]
    xbgdf_subset['xtarget'] = xbgdf_subset.geometry.x
    xbgdf_subset['ytarget'] = xbgdf_subset.geometry.y
    # Round vals
    xbgdf_subset = xbgdf_subset.round({'xtarget':2,'ytarget':2})
    # Bring old index over for merging
    xbgdf_subset['ind'] = gdf_proj['ind'].values

    # Merge dfs
    df = pd.merge(gdf_proj,xbgdf_subset,on="ind")

    # Round and convert coordinates to ints
    df['xtarget'] = df['xtarget'].round(decimals=0).astype(int)
    df['ytarget'] = df['ytarget'].round(decimals=0).astype(int)

    return df, ncolXB, nrowXB


def parse_BOMWaveFile(dt=None,waveCode=None):
    bomDate = str(str(dt.year)+
                    str(dt.month).zfill(2)+
                    str(dt.day).zfill(2))
    bomTime = str(str(dt.hour).zfill(2)+
            str(dt.minute).zfill(2))
    bomDT = str(bomDate+"T"+bomTime+"Z")
    fname = "%s.msh.%s.nc" % (waveCode,bomDT)

    return fname, bomDate, bomTime


def determineStormPeriods(df=None):
    """
    IMPORTANT: ASSUMES HOURLY WAVE FORECAST DATA
    """
    df['storm'] = np.where(df['hs']>=3., True, False)
    # Determine storm blips, remove all of them including the last one
    group_stormBlips = df[df['storm'] == True].groupby((df['storm'] != True).cumsum())
    indeces2Remove = []
    for k, v in group_stormBlips:
        if len(v) < 6:
            indeces2Remove = np.concatenate([indeces2Remove,v.index.values])
    # Drop these indeces from the waves timeseries
    df = df.drop(index=indeces2Remove).reset_index()
    # Determine quiet blips, remove all of them including the last one
    group_quietBlips = df[df['storm'] == False].groupby((df['storm'] != False).cumsum())
    indeces2Remove = []
    for k, v in group_quietBlips:
        if len(v) < 48:
            indeces2Remove = np.concatenate([indeces2Remove,v.index.values])
    # Drop these indeces from the waves timeseries
    df = df.drop(index=indeces2Remove).reset_index()
    # Now determine the actual storm periods
    group_storms = df[df['storm'] == True].groupby((df['storm'] != True).cumsum())
    storms_df = pd.DataFrame(columns=["storm_start","storm_end"])
    for k, v in group_storms:
        if len(v) >= 6:
            stormStart = v.time.values[0]
            stormEnd = v.time.values[-1]
            storms_df = storms_df.append({"storm_start":stormStart,
                            "storm_end":stormEnd},ignore_index=True)
    return storms_df