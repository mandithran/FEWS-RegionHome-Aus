import os, re
import numpy as np
import pandas as pd
import geopandas as gpd
import pytz
import xarray as xr
from datetime import datetime, timedelta

#============== Generate time series - GMT ==============#
def generateTimeSeries(forecast=None):

    """
    Generates a time series based on attributes of a
    forecast object. Forecast objects typically set in 
    initializeForecast.py or initializeHotspot.py. Attributes
    given in fewsForecast.py.

    Returns a dataframe
    """

    # Convert inputs to numpy timedelta64 objects
    deltat = np.timedelta64(forecast.deltat) # timestep for water level time series
    startTime = np.datetime64(forecast.startTime) # start time of forecast
    endTime = np.datetime64(forecast.endTime) # end time of forecast

    # Generate time series with numpy 
    timeSeries = np.arange(startTime,endTime+deltat,deltat)

    # Convert to dataframe
    dfts = pd.DataFrame(timeSeries,columns=["time_gmt"])
    # Set times as indeces
    dfts.index = dfts['time_gmt']
    dfts.index = pd.to_datetime(dfts.index, utc=True)
    dfts = dfts.drop(columns=['time_gmt'])

    return dfts

def loadTideData(ifile=None, forecast=None):

    """
    Loads the tide predictions from an input file using attributes from a
    forecast object.

    INPUTS:
        - ifile: Input file containing tide predictions 
        - forecast: Forecast object. Forecast objects typically set in 
          initializeForecast.py or initializeHotspot.py. Attributes given 
          in fewsForecast.py.

    Returns a dataframe containing tide predictions for the forecast
    interval. 
    """

    #============== Load tide data - MUST BE IN GMT ==============#
    # Load tide predictions as a dataframe
    dft = pd.read_csv(ifile, names=['datetime_gmt','tide_m'], header=0)
    # Set datetime as index in dataframe
    dft['datetime_gmt'] = pd.to_datetime(dft['datetime_gmt'], format="%d-%m-%Y %H:%M", utc=True)
    dft.index=dft['datetime_gmt']
    dft = dft.drop(columns=['datetime_gmt'])
    # Slice and dice the df
    dft = dft[(dft.index >= forecast.startTime) & (dft.index <= forecast.endTime)]

    return dft

#============== Interpolate tidal forecast at 10 m intervals ==============#
def interpSeries(series=None, forecast=None):
    """
    Interpolates a time series to the forecast.deltat (attribute specified)
    in initializeRegional.py, attributes listed in fewsForecast.py.

    INPUTS:
        - series: A dataframe containing the time series to interpolate
        - forecast: regionalForecast object, initialized in 
          initializeRegional.py, see fewsForecast.py for class definition.
    
    Outputs an interpolated time series as a dataframe.

    """
    # Convert timedelta object to a string in minutes
    deltat_min = int(round((forecast.deltat.seconds/60),0))
    upsampled = series.resample('%sT' % deltat_min, origin=forecast.startTime).asfreq()
    interpolated = upsampled.interpolate(method='linear')

    return interpolated


#============== Load surge data - MUST BE IN GMT ==============#
    # Parse rounded system time for filename

def loadSurgeData(surgePath=None, forecast=None):

    dfs = pd.read_csv(surgePath, names=['datetime_gmt','surge_m'], header=0)
    dfs['datetime_gmt'] = pd.to_datetime(dfs['datetime_gmt'], format="%Y-%m-%d %H:%M:%S")
    dfs.index=dfs['datetime_gmt']
    dfs = dfs.drop(columns=['datetime_gmt'])
    dfs = dfs.tz_localize(pytz.utc)
    dfs = dfs[(dfs.index >= forecast.startTime) & (dfs.index <= forecast.endTime)]

    return dfs


#======================== Process surge data ========================#
def processNSS_nc(forecast=None, nssDir=None, fname=None):

    """
    Extracts storm surge signal from BoM National Storm Surge (NSS) 
    forecast, provided as a netCDF file. netCDF file is fetched by the
    retrieveNSS.py script in the NSSDownload Module. The storm surge
    signal is extracted for a specific point, given by 
    forecast.lonSurge and forecast.latSurge. This point is determined
    manually as the most appropriate point for extracting the surge
    signal at a given hotspot location. The point lat/lon is set in 
    hotspotLocations.csv. 

    INPUTS:
        - forecast: hotspotForecast object. Should have lonSurge and
          latSurge attributes defined in the hotspotLocations.csv location
          set file. 
        - nssDir: Directory of the NSS file download
        - fname: The name of the netCDF file. 

    OUTPUT:
        - dfOut: The storm surge time series, including any desired spin-up
          window, and any extension of the storm surge time series beyond
          3 days


    Note: this funciton could potentially throw errors if the lat/lon
    given in hotspotLocations.csv doesn't match a lat/lon given on
    the NSS mesh. If that's the case, extract the index of the point
    that is closest to the point listed in hotspotLocations.csv.
    """
        
    # =================== Paths =================== #
    ifile = os.path.join(nssDir,fname)

    # Load dataset
    ds = xr.open_dataset(ifile)

    #print(ds.keys)
    # ds.keys will reveal that the NetCDF file does not have lat/lon dimensions - it has a "point" and "time" dimensions
    # These "point" dimensions are essentially the index of a given point
    # The "point dimension" has the same shape as the lat and lon fields
    # This is because this is not a regular grid; each point has a unique lat, lon value
    # The following will return the index that matches the lat/lon point of interest
    # This index allows for selection of subsets of the xarray dataset (the loaded netCDF)
    df = pd.DataFrame({"lon":ds.coords['lon'].values,"lat":ds.coords['lat'].values})
    # Return index of the point that matches the lat/lon point. If this doesn't work, 
    # try a function that returns the closest point. Methods for this are given in 
    # preprocessMainRegional.py
    ind = df[(df['lon']==forecast.lonSurge) & 
            (df['lat']==forecast.latSurge)].index

    # Select surge timeseries for the point of interest
    surge = ds.surge[ind].values

    # Create new pandas df with the surge time series 
    dfOut = pd.DataFrame({"Datetime_gmt":ds.coords['time'].values,
                    "surge (m)":surge[0]
                    })

    # Add 12-hour spin-up timeseries that retains the first value
    # of the surge forecast
    # Find timestep of surge time series
    dt_delta = dfOut.Datetime_gmt[1]-dfOut.Datetime_gmt[0]
    surgeStartTime = dfOut.Datetime_gmt[0]
    surgeEndTime = dfOut.Datetime_gmt.iloc[-1]
    # Get the spin-up time from forecast attribute
    spinUpTime = forecast.spinUpWindow # argument in hours
    # Compute the start/end times of the spin-up period (default: 12 hours)
    spinUpEndTime = surgeStartTime
    spinUpStartTime = spinUpEndTime-(spinUpTime)
    # Generate the time series for the spin-up period
    spinUp_series = pd.date_range(start=spinUpStartTime,
                            end=spinUpEndTime,
                            freq=dt_delta)
    # Convert this time series to a dataframe
    spinUp_df = pd.DataFrame({"Datetime_gmt":spinUp_series,
                            "surge (m)":dfOut["surge (m)"][0]
                            }).set_index("Datetime_gmt")

    # Concatenate spin-up time series with real surge time series
    dfOut = dfOut.set_index("Datetime_gmt")
    dfOut = pd.concat([spinUp_df,dfOut])

    # Set timezone info for surge time series (ASSUMES GMT/UTC)
    dfOut = dfOut.tz_localize(pytz.utc)

    # If the forecast horizon is greater than 3 days, add an additional extension 
    # of the timeseries that sets the surge signal to 0 m for the remainder of 
    # the forecast window. This is done because the desired foredast window is 7
    # days, but the storm surge forecast only goes for 3 days. So we taper the
    # storm surge signal to 0 m for the remainder of the 7-day forecast window.
    if forecast.forecastHorizon > timedelta(days=int(3)):
        # Start time of the extended storm surge signal
        extendedTSStartTime = dfOut.index[-1] + dt_delta
        # Example: if you want a 7-day forecast, you have 
        # four days where the surge forecast needs to be
        # extended (forecast.forecastHorizon - (surgeEndTime-surgeStartTime))
        extensionDuration = forecast.forecastHorizon - (surgeEndTime-surgeStartTime)
        extendedTSEndTime = dfOut.index[-1] + extensionDuration
        # Generate the extended time series for the surge signal
        extendedSeries = pd.date_range(start=extendedTSStartTime,
                            end=extendedTSEndTime,
                            freq=dt_delta)
        # Convert above time series to a dataframe
        extended_df = pd.DataFrame({"Datetime_gmt":extendedSeries,
                            "surge (m)":0
                            }).set_index("Datetime_gmt")
        # Concatenate this to the storm surge series df
        dfOut = pd.concat([dfOut,extended_df])

    # File name based on site and date time given in original nc file
    #dateTime = re.split("[_.]", fname)[3]
    #ofname = "nss_%s_%s.csv" % (forecast.siteName, dateTime)
    #ofPath = os.path.join(importDir,ofname)
    #dfOut.to_csv(ofPath)

    # The end result should now be a storm surge series, with a spin-
    # up window, and with a four-day extension of the 3-day forecast,
    # where the value of the storm surge is tapered to 0 m. 
    return dfOut


#============== Extract surge data ==============#
def extractNSS(forecast=None, ds=None, nss_lat=None, nss_lon=None):

    """
    Extracts the surge forecast from the NSS output from the BoM.
    The point you want to extract needs to be precisely known
    (see nearGeom function in preProcWaves - this can provide
    the precise nearest point on the mesh).

    Inputs:
    forecast: FEWS forecast object, can be a hotspot or regional
      forecast. Defined in initializeRegional.py, initializeHotpsot.py,
      class structure is provided in fewsForecast.py
    ds: xarray dataset containing the netCDF storm surge output.
    nss_lat: latitude of the point of interest where NSS surge forecast
      will be extracted from.
    nss_lon: ditto but for the longitude of the point

    Output:
    Returns a dataframe with the surge forecast time series at the
    given point. 
    """

    # Select dataset by point of interest
    ds = ds[['surge']]
    ds = ds.where(ds.lat==nss_lat, drop=True)
    ds = ds.where(ds.lon==nss_lon, drop=True)
    
    # Select surge timeseries for the point of interest
    surge = ds.surge.values[0]

    # Create new pandas df
    dfOut = pd.DataFrame({"Datetime_gmt":ds.coords['time'].values,
                    "surge (m)":surge
                    })

    # Time parameters
    dt_delta = dfOut.Datetime_gmt[1]-dfOut.Datetime_gmt[0]
    surgeStartTime = dfOut.Datetime_gmt[0]
    surgeEndTime = dfOut.Datetime_gmt.iloc[-1]

    # Set timezone info
    dfOut = dfOut.set_index("Datetime_gmt")
    dfOut = dfOut.tz_localize(pytz.utc)


    # If the forecast horizon is greater than 3 days, 
    # add an additional extension of the timeseries that sets the surge signal to
    # 0 m for the remainder of the forecast window
    if forecast.forecastHorizon > timedelta(days=int(3)):
        extendedTSStartTime = dfOut.index[-1] + dt_delta
        # Example: if you want a 7-day forecast, you have 
        # four days where the surge forecast needs to be
        # extended (forecast.forecastHorizon - (surgeEndTime-surgeStartTime))
        extensionDuration = forecast.forecastHorizon - (surgeEndTime-surgeStartTime)
        extendedTSEndTime = dfOut.index[-1] + extensionDuration
        extendedSeries = pd.date_range(start=extendedTSStartTime,
                            end=extendedTSEndTime,
                            freq=dt_delta)
        extended_df = pd.DataFrame({"Datetime_gmt":extendedSeries,
                            "surge (m)":0
                            }).set_index("Datetime_gmt")
        # Concatenate this to the water level series df
        dfOut = pd.concat([dfOut,extended_df])


    return dfOut